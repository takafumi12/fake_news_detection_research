{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Lambda, LSTM, Embedding, Conv1D, TimeDistributed, Add\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def dump(value, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(value, f)\n",
    "          \n",
    "def save_model(model, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/dataset/'\n",
    "model_path = '../model/fake_news_classifier_model/'\n",
    "user2ind = load(dataset_path+'user2ind.pkl')\n",
    "eid2ind = load(dataset_path+'eid2ind.pkl')\n",
    "eid_train = load(dataset_path+'eid_train.pkl')\n",
    "eid_test = load(dataset_path+'eid_test.pkl')\n",
    "X = load(dataset_path+'X.pkl')\n",
    "X_dict = load(dataset_path+'X_dict.pkl')\n",
    "y_dict = load(dataset_path+'y_dict.pkl')\n",
    "dict_ = load(dataset_path+'dict_.pkl')\n",
    "subX_dict = load(dataset_path+'subX_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "matrix_main is used for LSTM input.\n",
    "matrix_sub is used for the scoring module.\n",
    "'''\n",
    "acc=0\n",
    "\n",
    "nb_users = len(user2ind)\n",
    "nb_events = len(eid2ind)\n",
    "nb_features = 2+20+100    # (#temporal, #user, #doc)\n",
    "dim_hidden = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Main part #####\n",
    "inputs = Input(shape=(None, nb_features))\n",
    "emb_out = TimeDistributed(Dense(100, activation='tanh'))(inputs)    # W_e\n",
    "emb_out = Dropout(0.2)(emb_out)\n",
    "lstm_out = LSTM(dim_hidden, activation='tanh', return_sequences=False)(emb_out)    #(None, dim_hidden)\n",
    "lstm_out = Dense(100, activation='tanh')(lstm_out)     # (None, 100) W_r\n",
    "lstm_out = Dropout(0.2)(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Sub part #####\n",
    "nb_score = 1\n",
    "nb_expand = 100\n",
    "sub_input = Input(shape=(None, nb_feature_sub))\n",
    "user_vec = TimeDistributed(Dense(nb_expand, activation='tanh',\n",
    "                                 kernel_regularizer=keras.regularizers.l2(0.01)))(sub_input)   # (None, None, nb_expand)\n",
    "sub_h = TimeDistributed(Dense(nb_score, activation='sigmoid'))(user_vec)    # (None, None, nb_score)\n",
    "z = Lambda(lambda x: K.mean(x, axis=1), output_shape=lambda s: (s[0], s[2]))(sub_h)    #(None, nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Concatenate #####\n",
    "out1 = keras.layers.Dense(1, activation='sigmoid')(lstm_out)\n",
    "concat_out = Add()([out1, z])\n",
    "# concat_out = merge([rnn_out, z], mode='concat', concat_axis=1)\n",
    "# concat_out = concatenate([rnn_out, z], axis=1)\n",
    "\n",
    "##### Classifier #####\n",
    "# outputs = Dense(1, activation='sigmoid')(concat_out)\n",
    "# outputs = Dense(1, activation='sigmoid')(concat_out)\n",
    "outputs = concat_out\n",
    "\n",
    "##### Model #####\n",
    "hvector = Model(inputs=[inputs, sub_input], outputs=concat_out)\n",
    "zscore = Model(inputs=sub_input, outputs=sub_h)\n",
    "model = Model(inputs=[inputs, sub_input], outputs=outputs)\n",
    "uvector = Model(inputs=sub_input, outputs=user_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compile #####\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "print(\"Model is compiled.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "### Training... ###\n",
    "nb_epoch = 30\n",
    "    \n",
    "for ep in range(nb_epoch+1):\n",
    "    print(\"{} epoch!!!!!!!!\".format(ep))\n",
    "    ##### Looping for eid_train #####\n",
    "    losses = []\n",
    "    for ii, eid in enumerate(eid_train):\n",
    "        \n",
    "        print(f'eid:{eid}')\n",
    "\n",
    "        trainX = X_dict[eid]\n",
    "        trainX = trainX.astype(np.float32)\n",
    "        \n",
    "        sub_trainX = subX_dict[eid]\n",
    "        sub_trainX = sub_trainX.astype(np.float32)\n",
    "        \n",
    "        trainY = y_dict[eid]\n",
    "        \n",
    "        if ep % 10 == 0:\n",
    "            h = model.fit([trainX[np.newaxis,:,:], sub_trainX[np.newaxis,:,:]], np.array([trainY]), batch_size=1, epochs=1, verbose=2)\n",
    "        else:\n",
    "            h = model.fit([trainX[np.newaxis,:,:], sub_trainX[np.newaxis,:,:]], np.array([trainY]), batch_size=1, epochs=1, verbose=0)\n",
    "        \n",
    "        losses.append(h.history['loss'][0])\n",
    "    print(\"%% mean loss : {}\".format(np.mean(losses)))\n",
    "\n",
    "    ### Evaluation ###\n",
    "    preds = []\n",
    "    y_test = []\n",
    "    \n",
    "    for ii, eid in enumerate(eid_test):\n",
    "\n",
    "        testX = X_dict[eid]\n",
    "        testX = testX.astype(np.float32)\n",
    "        \n",
    "        sub_testX = subX_dict[eid]\n",
    "        sub_testX = sub_testX.astype(np.float32)\n",
    "        \n",
    "        y_test.append(y_dict[eid])\n",
    "\n",
    "        pred = model.predict([np.array([testX]), np.array([sub_testX])], verbose=0)\n",
    "        preds.append(pred[0,0])\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds>0.5\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    print(\"%%% Test results {} samples %%%\".format(len(y_test)))\n",
    "    print(\"accuracy: {}\".format((tp+tn)/(tp+tn+fp+fn)))\n",
    "    print(\"precision : {:.4f} / {:.4f}\".format(tp/(tp+fp), tn/(fn+tn)))\n",
    "    print(\"recall : {:.4f} / {:.4f}\".format(tp/(tp+fn), tn/(fp+tn)))\n",
    "    print(\"F1 score : {:.4f} / {:.4f}\".format(2*tp/(2*tp+fp+fn), 2*tn/(2*tn+fp+fn)))\n",
    "        \n",
    "    if acc < (tp+tn)/(tp+tn+fp+fn):\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        print(\"%%%%%%%%%% Save model\\t acc:{} %%%%%%%%%%%%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, model_path+'fake_news_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
